# Visual Odometry System - Project Plan

## üìã Overview

**M·ª•c ti√™u:** X√¢y d·ª±ng h·ªá th·ªëng Visual Odometry (VO) production-ready s·ª≠ d·ª•ng camera ƒë∆°n (Monocular VO) ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng v√† t√°i t·∫°o qu·ªπ ƒë·∫°o chuy·ªÉn ƒë·ªông c·ªßa camera trong kh√¥ng gian 3D. H·ªá th·ªëng h·ªó tr·ª£ nhi·ªÅu thu·∫≠t to√°n feature extraction v√† cho ph√©p ng∆∞·ªùi d√πng ch·ªçn l·ª±a ƒë·ªÉ so s√°nh hi·ªáu nƒÉng.

**T·∫°i sao:** Visual Odometry l√† n·ªÅn t·∫£ng cho nhi·ªÅu ·ª©ng d·ª•ng nh∆∞ robot navigation, autonomous vehicles, AR/VR. D·ª± √°n n√†y t·∫°o ra c√¥ng c·ª• linh ho·∫°t ƒë·ªÉ nghi√™n c·ª©u v√† so s√°nh c√°c thu·∫≠t to√°n VO kh√°c nhau.

---

## üéØ Project Type

**BACKEND/STANDALONE APPLICATION** (Computer Vision Application)

- Kh√¥ng ph·∫£i Web App ‚Üí Kh√¥ng d√πng `frontend-specialist`
- Kh√¥ng ph·∫£i Mobile App ‚Üí Kh√¥ng d√πng `mobile-developer`
- ·ª®ng d·ª•ng desktop ƒë·ªôc l·∫≠p v·ªõi GUI ‚Üí D√πng `backend-specialist`, `performance-optimizer`

---

## ‚úÖ Success Criteria

| Ti√™u Ch√≠           | ƒê·ªãnh Nghƒ©a Th√†nh C√¥ng                                                             |
| ------------------ | --------------------------------------------------------------------------------- |
| **Ch·ª©c nƒÉng**      | H·ªá th·ªëng ch·∫°y ƒë∆∞·ª£c v·ªõi c·∫£ live camera v√† video file, t√°i t·∫°o qu·ªπ ƒë·∫°o 3D ch√≠nh x√°c |
| **Thu·∫≠t to√°n**     | H·ªó tr·ª£ ƒë·∫ßy ƒë·ªß 4 thu·∫≠t to√°n: FAST, ORB, SIFT, Lucas-Kanade Optical Flow            |
| **Hi·ªáu nƒÉng**      | ƒê·∫°t ‚â•10 FPS v·ªõi CPU (Intel i5/M1 ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng) v·ªõi video 720p                 |
| **ƒê·ªô ch√≠nh x√°c**   | Drift error < 5% tr√™n ƒëo·∫°n video 30 gi√¢y (so v·ªõi ground truth n·∫øu c√≥)             |
| **Cross-platform** | Ch·∫°y m∆∞·ª£t tr√™n c·∫£ macOS (M1/Intel) v√† Windows 10/11                               |
| **UX**             | GUI r√µ r√†ng, d·ªÖ ch·ªçn thu·∫≠t to√°n, hi·ªÉn th·ªã real-time trajectory                    |
| **Production**     | Error handling ƒë·∫ßy ƒë·ªß, logging, camera calibration, config file                   |

---

## üõ†Ô∏è Tech Stack

| Component              | Technology                           | Rationale                                           |
| ---------------------- | ------------------------------------ | --------------------------------------------------- |
| **Environment**        | Conda environment "vo"               | Isolated dependencies, reproducible setup           |
| **Core Language**      | Python 3.10+                         | Ecosystem m·∫°nh cho CV, OpenCV native support        |
| **Computer Vision**    | OpenCV 4.8+                          | Feature extraction, camera matrix, essential matrix |
| **Numerical**          | NumPy 1.24+                          | Matrix operations, linear algebra                   |
| **3D Visualization**   | Open3D ho·∫∑c Matplotlib 3D            | Real-time 3D trajectory plotting                    |
| **GUI Framework**      | PyQt5 ho·∫∑c Tkinter                   | Cross-platform, algorithm selection, video controls |
| **CPU Optimization**   | NumPy vectorization, multi-threading | T·ªëi ∆∞u CPU cho feature detection/matching           |
| **Camera Calibration** | OpenCV calibration module            | Intrinsic/extrinsic parameters                      |
| **Video I/O**          | OpenCV VideoCapture                  | USB camera v√† video file support                    |
| **Config Management**  | YAML/JSON                            | Algorithm parameters, camera settings               |
| **Testing**            | pytest                               | Unit tests cho t·ª´ng module                          |
| **Logging**            | Python logging                       | Debug v√† performance monitoring                     |

**Trade-offs:**

- **Open3D vs Matplotlib 3D:** Open3D m·∫°nh h∆°n cho point cloud nh∆∞ng dependency l·ªõn h∆°n. Matplotlib nh·∫π h∆°n, ƒë·ªß cho trajectory.
- **PyQt5 vs Tkinter:** PyQt5 ƒë·∫πp h∆°n, nhi·ªÅu widget h∆°n nh∆∞ng c·∫ßn license cho commercial. Tkinter built-in, ƒë∆°n gi·∫£n h∆°n.
- **CPU-only:** ƒê∆°n gi·∫£n setup, cross-platform t·ªët h∆°n, nh∆∞ng FPS th·∫•p h∆°n GPU (10-12 FPS vs 25-30 FPS).

---

## üìÅ File Structure

```
Visual-odometry/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ environment.yml               # Conda environment definition
‚îú‚îÄ‚îÄ requirements.txt              # Pip requirements (backup)
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ camera_params.yaml        # Camera calibration parameters
‚îÇ   ‚îú‚îÄ‚îÄ algorithm_config.yaml     # Algorithm-specific settings
‚îÇ   ‚îî‚îÄ‚îÄ default_config.yaml       # Default runtime config
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ camera.py             # Camera input handler (live/file)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py       # Grayscale, denoise
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vo_pipeline.py        # Main VO orchestrator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trajectory.py         # Trajectory accumulation
‚îÇ   ‚îú‚îÄ‚îÄ algorithms/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_algorithm.py     # Abstract base class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fast_detector.py      # FAST feature detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orb_detector.py       # ORB feature detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sift_detector.py      # SIFT feature detection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lk_optical_flow.py    # Lucas-Kanade Optical Flow
‚îÇ   ‚îú‚îÄ‚îÄ motion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ essential_matrix.py   # Essential matrix estimation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pose_estimation.py    # Recover R, t from E
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scale_estimation.py   # Monocular scale ambiguity handling
‚îÇ   ‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trajectory_3d.py      # 3D trajectory plotter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_display.py      # Video frame + keypoints overlay
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stats_panel.py        # FPS, drift, algorithm info
‚îÇ   ‚îú‚îÄ‚îÄ gui/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main_window.py        # Main GUI window
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ algorithm_selector.py # Algorithm selection widget
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ video_controls.py     # Play/pause/speed controls
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ calibration.py        # Camera calibration utilities
‚îÇ       ‚îú‚îÄ‚îÄ logger.py             # Logging setup
‚îÇ       ‚îî‚îÄ‚îÄ config_loader.py      # YAML config parser
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_algorithms.py
‚îÇ   ‚îú‚îÄ‚îÄ test_motion_estimation.py
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ sample_videos/            # Test videos
‚îÇ   ‚îî‚îÄ‚îÄ calibration_images/       # Camera calibration images
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md           # System architecture
‚îÇ   ‚îú‚îÄ‚îÄ ALGORITHMS.md             # Algorithm comparison
‚îÇ   ‚îî‚îÄ‚îÄ CALIBRATION.md            # How to calibrate camera
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ calibrate_camera.py       # Camera calibration script
    ‚îî‚îÄ‚îÄ benchmark.py              # Performance benchmarking
```

---

## üìä Task Breakdown

### **P0: Foundation Setup** (Dependency: None)

#### Task 1.1: Project Initialization

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`, `clean-code`
- **Priority:** P0
- **Dependencies:** None
- **INPUT:** Requirements, tech stack
- **OUTPUT:**
    - `environment.yml` cho conda environment "vo"
    - `requirements.txt` v·ªõi pinned versions (backup)
    - `setup.py` for package installation
    - Folder structure theo design
    - `.gitignore` (data/, \*.pyc, **pycache**, .conda/)
- **VERIFY:**
    - `conda env create -f environment.yml` t·∫°o environment th√†nh c√¥ng
    - `conda activate vo` k√≠ch ho·∫°t environment
    - `pip install -e .` ch·∫°y th√†nh c√¥ng, import src modules kh√¥ng l·ªói

#### Task 1.2: Configuration System

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P0
- **Dependencies:** Task 1.1
- **INPUT:** Config requirements (camera params, algorithm settings)
- **OUTPUT:**
    - `config_loader.py` v·ªõi YAML parsing
    - `default_config.yaml`, `camera_params.yaml`, `algorithm_config.yaml`
- **VERIFY:** Load config th√†nh c√¥ng, override parameters ho·∫°t ƒë·ªông

#### Task 1.3: Logging System

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P0
- **Dependencies:** Task 1.1
- **INPUT:** Logging requirements (debug, info, error levels)
- **OUTPUT:**
    - `logger.py` v·ªõi file v√† console handlers
    - Log rotation setup
- **VERIFY:** Log messages xu·∫•t hi·ªán ƒë√∫ng format, file logs ƒë∆∞·ª£c t·∫°o

---

### **P1: Core Camera Input** (Dependency: P0)

#### Task 2.1: Camera Input Handler

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`
- **Priority:** P1
- **Dependencies:** Task 1.1, 1.2, 1.3
- **INPUT:** Live camera v√† video file requirements
- **OUTPUT:**
    - `camera.py` v·ªõi class `CameraInput`
    - Support `VideoCapture` cho c·∫£ webcam (device ID) v√† file path
    - Frame buffering n·∫øu c·∫ßn
- **VERIFY:**
    - M·ªü webcam th√†nh c√¥ng, ƒë·ªçc ƒë∆∞·ª£c frames
    - M·ªü video file th√†nh c√¥ng, ƒë·ªçc ƒë∆∞·ª£c frames
    - FPS tracking ch√≠nh x√°c

#### Task 2.2: Preprocessing Pipeline

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P1
- **Dependencies:** Task 2.1
- **INPUT:** Raw BGR frames t·ª´ camera
- **OUTPUT:**
    - `preprocessor.py` v·ªõi grayscale conversion
    - Optional: Gaussian blur ƒë·ªÉ denoise
    - Resize n·∫øu c·∫ßn (maintain aspect ratio)
- **VERIFY:** Output frame shape ƒë√∫ng, grayscale conversion ch√≠nh x√°c

---

### **P2: Algorithm Implementation** (Dependency: P1)

#### Task 3.1: Base Algorithm Interface

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`, `clean-code`
- **Priority:** P2
- **Dependencies:** Task 2.2
- **INPUT:** Algorithm requirements (detect, describe, match)
- **OUTPUT:**
    - `base_algorithm.py` v·ªõi Abstract Base Class
    - Methods: `detect()`, `describe()`, `match()`
    - Common interface cho t·∫•t c·∫£ algorithms
- **VERIFY:** Subclass c√≥ th·ªÉ inherit v√† override methods

#### Task 3.2: FAST Feature Detector

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P2
- **Dependencies:** Task 3.1
- **INPUT:** Grayscale frame
- **OUTPUT:**
    - `fast_detector.py` implement FAST
    - Keypoints detection v·ªõi configurable threshold
- **VERIFY:** Detect keypoints tr√™n test image, visualize keypoints

#### Task 3.3: ORB Feature Detector

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P2
- **Dependencies:** Task 3.1
- **INPUT:** Grayscale frame
- **OUTPUT:**
    - `orb_detector.py` implement ORB
    - Keypoints + descriptors
- **VERIFY:** Detect v√† match keypoints gi·ªØa 2 frames

#### Task 3.4: SIFT Feature Detector

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P2
- **Dependencies:** Task 3.1
- **INPUT:** Grayscale frame
- **OUTPUT:**
    - `sift_detector.py` implement SIFT
    - Keypoints + descriptors (128-dim)
- **VERIFY:** SIFT detection ho·∫°t ƒë·ªông, match accuracy t·ªët h∆°n FAST/ORB

#### Task 3.5: Lucas-Kanade Optical Flow

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P2
- **Dependencies:** Task 3.1
- **INPUT:** 2 consecutive grayscale frames
- **OUTPUT:**
    - `lk_optical_flow.py` implement Lucas-Kanade
    - Track keypoints t·ª´ frame tr∆∞·ªõc sang frame sau
- **VERIFY:** Tracking keypoints m∆∞·ª£t m√†, outlier rejection ho·∫°t ƒë·ªông

---

### **P3: Motion Estimation** (Dependency: P2)

#### Task 4.1: Essential Matrix Estimation

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`
- **Priority:** P3
- **Dependencies:** Task 3.2, 3.3, 3.4, 3.5
- **INPUT:** Matched keypoints t·ª´ 2 frames, camera intrinsic matrix K
- **OUTPUT:**
    - `essential_matrix.py` v·ªõi `cv2.findEssentialMat()`
    - RANSAC outlier rejection
    - Inlier mask return
- **VERIFY:** Essential matrix c√≥ rank 2, satisfies E^T \* E = 0

#### Task 4.2: Pose Estimation (R, t Recovery)

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P3
- **Dependencies:** Task 4.1
- **INPUT:** Essential matrix E, matched points
- **OUTPUT:**
    - `pose_estimation.py` v·ªõi `cv2.recoverPose()`
    - Extract Rotation R v√† Translation t
    - Handle 4 possible solutions ‚Üí ch·ªçn ƒë√∫ng
- **VERIFY:** R l√† rotation matrix (det(R) = 1, R^T \* R = I), t unit vector

#### Task 4.3: Scale Estimation (Monocular)

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`
- **Priority:** P3
- **Dependencies:** Task 4.2
- **INPUT:** Translation vector t (ambiguous scale)
- **OUTPUT:**
    - `scale_estimation.py` v·ªõi strategy:
        - Option 1: Assume constant velocity
        - Option 2: Use ground truth n·∫øu c√≥
        - Option 3: Heuristic (median depth estimation)
- **VERIFY:** Trajectory kh√¥ng explode ho·∫∑c collapse, reasonable scale

---

### **P4: VO Pipeline Integration** (Dependency: P3)

#### Task 5.1: Trajectory Accumulation

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P4
- **Dependencies:** Task 4.3
- **INPUT:** R, t t·ª´ m·ªói frame pair
- **OUTPUT:**
    - `trajectory.py` v·ªõi class `Trajectory`
    - Accumulate poses: `T_world = T_world * T_current`
    - Store 3D positions (x, y, z) history
- **VERIFY:** Trajectory array kh√¥ng c√≥ NaN, infinity

#### Task 5.2: Main VO Pipeline

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P4
- **Dependencies:** Task 5.1, all P2, P3 tasks
- **INPUT:** Video stream, selected algorithm
- **OUTPUT:**
    - `vo_pipeline.py` orchestrate:
        1. Read frame ‚Üí Preprocess
        2. Feature detection/tracking
        3. Motion estimation
        4. Trajectory update
    - Loop cho to√†n b·ªô video
- **VERIFY:** Pipeline ch·∫°y end-to-end, output trajectory h·ª£p l√Ω

---

### **P5: Visualization** (Dependency: P4)

#### Task 6.1: 3D Trajectory Visualization

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P5
- **Dependencies:** Task 5.2
- **INPUT:** Trajectory 3D positions
- **OUTPUT:**
    - `trajectory_3d.py` v·ªõi Matplotlib 3D ho·∫∑c Open3D
    - Real-time update plot (every N frames)
    - Camera orientation visualization (optional)
- **VERIFY:** 3D plot hi·ªÉn th·ªã ƒë√∫ng, rotate/zoom ho·∫°t ƒë·ªông

#### Task 6.2: Frame Display with Keypoints

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P5
- **Dependencies:** Task 5.2
- **INPUT:** Current frame, detected keypoints
- **OUTPUT:**
    - `frame_display.py` overlay keypoints l√™n video
    - Matches visualization (lines gi·ªØa frames n·∫øu d√πng matching)
- **VERIFY:** Keypoints hi·ªÉn th·ªã r√µ r√†ng tr√™n video

#### Task 6.3: Stats Panel

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P5
- **Dependencies:** Task 5.2
- **INPUT:** Runtime stats (FPS, num keypoints, inliers, etc.)
- **OUTPUT:**
    - `stats_panel.py` hi·ªÉn th·ªã real-time metrics
    - Text overlay ho·∫∑c separate panel
- **VERIFY:** Stats update real-time, ch√≠nh x√°c

---

### **P6: GUI Development** (Dependency: P5)

#### Task 7.1: Main Window

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P6
- **Dependencies:** Task 6.1, 6.2, 6.3
- **INPUT:** All visualization components
- **OUTPUT:**
    - `main_window.py` v·ªõi PyQt5/Tkinter
    - Layout: Video frame b√™n tr√°i, 3D plot b√™n ph·∫£i, controls d∆∞·ªõi
- **VERIFY:** Window hi·ªÉn th·ªã ƒë√∫ng layout, resize ho·∫°t ƒë·ªông

#### Task 7.2: Algorithm Selector

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P6
- **Dependencies:** Task 7.1
- **INPUT:** List algorithms (FAST, ORB, SIFT, LK)
- **OUTPUT:**
    - `algorithm_selector.py` v·ªõi dropdown/radio buttons
    - Signal khi user ƒë·ªïi algorithm
- **VERIFY:** Ch·ªçn algorithm ‚Üí pipeline restart v·ªõi algorithm m·ªõi

#### Task 7.3: Video Controls

- **Agent:** `backend-specialist`
- **Skill:** `clean-code`
- **Priority:** P6
- **Dependencies:** Task 7.1
- **INPUT:** Video playback state
- **OUTPUT:**
    - `video_controls.py` v·ªõi Play/Pause/Stop/Speed
    - File browser ƒë·ªÉ ch·ªçn video
    - Camera selection dropdown
- **VERIFY:** Controls ho·∫°t ƒë·ªông, video pause/resume ch√≠nh x√°c

---

### **P7: Camera Calibration** (Dependency: None, can parallel)

#### Task 8.1: Calibration Utilities

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`
- **Priority:** P7
- **Dependencies:** Task 1.1
- **INPUT:** Checkerboard calibration images
- **OUTPUT:**
    - `calibration.py` v·ªõi calibration pipeline
    - Save/load camera matrix K v√† distortion coefficients
    - `scripts/calibrate_camera.py` standalone script
- **VERIFY:** Calibrate camera v·ªõi checkerboard, K matrix h·ª£p l√Ω (fx, fy ~ focal length)

---

### **P8: Performance Optimization** (Dependency: P6)

#### Task 9.1: CPU Optimization

- **Agent:** `performance-optimizer`
- **Skill:** `performance-profiling`
- **Priority:** P8
- **Dependencies:** Task 5.2
- **INPUT:** Baseline VO pipeline
- **OUTPUT:**
    - NumPy vectorization cho matrix operations
    - Optimize feature detection parameters (reduce keypoints n·∫øu c·∫ßn)
    - Caching cho camera matrix, config
    - Profiling v·ªõi cProfile ƒë·ªÉ t√¨m bottlenecks
- **VERIFY:** FPS tƒÉng ‚â•30% so v·ªõi baseline

#### Task 9.2: Multi-threading

- **Agent:** `performance-optimizer`
- **Skill:** `performance-profiling`
- **Priority:** P8
- **Dependencies:** Task 9.1
- **INPUT:** Single-threaded pipeline
- **OUTPUT:**
    - Separate threads: frame capture, processing, visualization
    - Thread-safe queues
- **VERIFY:** FPS tƒÉng th√™m, kh√¥ng deadlock

---

### **P9: Testing** (Dependency: P8)

#### Task 10.1: Unit Tests

- **Agent:** `test-engineer`
- **Skill:** `testing-patterns`
- **Priority:** P9
- **Dependencies:** All implementation tasks
- **INPUT:** All modules
- **OUTPUT:**
    - `tests/test_algorithms.py` test t·ª´ng algorithm
    - `tests/test_motion_estimation.py` test E, R, t
    - `tests/test_preprocessing.py` test preprocessing
    - Coverage ‚â•70%
- **VERIFY:** `pytest` pass t·∫•t c·∫£ tests

#### Task 10.2: Integration Tests

- **Agent:** `test-engineer`
- **Skill:** `testing-patterns`
- **Priority:** P9
- **Dependencies:** Task 10.1
- **INPUT:** Full pipeline
- **OUTPUT:**
    - `tests/test_integration.py` test end-to-end
    - Test v·ªõi sample video, verify trajectory shape
- **VERIFY:** Integration test pass, trajectory kh√¥ng drift qu√° 10%

#### Task 10.3: Performance Benchmarks

- **Agent:** `performance-optimizer`
- **Skill:** `performance-profiling`
- **Priority:** P9
- **Dependencies:** Task 10.2
- **INPUT:** Sample videos (720p, 1080p)
- **OUTPUT:**
    - `scripts/benchmark.py` benchmark FPS cho t·ª´ng algorithm
    - CSV report: Algorithm, Resolution, FPS, Memory, CPU Usage
    - Include multi-threading ON/OFF comparison
- **VERIFY:** FAST ‚â•15 FPS, ORB ‚â•10 FPS, SIFT ‚â•6 FPS tr√™n 720p (CPU)

---

### **P10: Documentation** (Dependency: P9)

#### Task 11.1: Code Documentation

- **Agent:** `documentation-writer`
- **Skill:** `documentation-templates`
- **Priority:** P10
- **Dependencies:** All implementation
- **INPUT:** Source code
- **OUTPUT:**
    - Docstrings cho t·∫•t c·∫£ public functions/classes
    - Type hints (Python 3.10+)
- **VERIFY:** `pydoc` generate docs th√†nh c√¥ng

#### Task 11.2: User Documentation

- **Agent:** `documentation-writer`
- **Skill:** `documentation-templates`
- **Priority:** P10
- **Dependencies:** Task 11.1
- **INPUT:** System functionality
- **OUTPUT:**
    - `README.md`: Installation, Quick Start, Usage
    - `docs/ARCHITECTURE.md`: System design
    - `docs/ALGORITHMS.md`: Algorithm comparison table
    - `docs/CALIBRATION.md`: How to calibrate camera
- **VERIFY:** Follow README ‚Üí c√≥ th·ªÉ run app th√†nh c√¥ng

---

## üîç Phase X: Final Verification

> üî¥ **CRITICAL:** T·∫•t c·∫£ checks n√†y PH·∫¢I pass tr∆∞·ªõc khi ƒë√°nh d·∫•u project complete.

### 1. Functional Tests

```bash
# Activate conda environment first
conda activate vo

# Run all unit tests
pytest tests/ -v --cov=src --cov-report=html

# Expected: Coverage ‚â•70%, all tests pass
```

### 2. Integration Test

```bash
# Activate environment
conda activate vo

# Run v·ªõi sample video
python src/main.py --video data/sample_videos/corridor.mp4 --algorithm ORB

# Expected:
# - Video plays smoothly
# - 3D trajectory displayed
# - No crashes
# - FPS ‚â•10 on 720p video (CPU)
```

### 3. Algorithm Verification (Manual)

- [ ] Test FAST: Keypoints detected, trajectory reasonable
- [ ] Test ORB: Keypoints detected, trajectory reasonable
- [ ] Test SIFT: Keypoints detected, trajectory reasonable
- [ ] Test Lucas-Kanade: Optical flow tracking smooth
- [ ] Switch algorithms mid-video: No crash, restart correctly

### 4. Cross-Platform Test

```bash
# macOS (M1/Intel)
python src/main.py --camera 0

# Windows (GPU)
python src/main.py --camera 0

# Expected: Both run smoothly, no platform-specific bugs
```

### 5. Performance Benchmarks

```bash
# Activate environment
conda activate vo

python scripts/benchmark.py --video data/sample_videos/test_720p.mp4

# Expected Output (CPU):
# FAST:  15-20 FPS
# ORB:   10-15 FPS
# SIFT:  6-10 FPS
# LK:    20-25 FPS (fastest)
```

### 6. CPU Performance Profiling

```bash
# Activate environment
conda activate vo

# Profile v·ªõi cProfile
python -m cProfile -o profile.stats src/main.py --video data/sample_videos/test_720p.mp4 --algorithm ORB

# Analyze bottlenecks
python -c "import pstats; p = pstats.Stats('profile.stats'); p.sort_stats('cumulative'); p.print_stats(20)"

# Expected: Feature detection v√† matching chi·∫øm ‚â•60% runtime
```

### 7. Camera Calibration Test

```bash
# Activate environment
conda activate vo

python scripts/calibrate_camera.py --images data/calibration_images/ --output config/camera_params.yaml

# Expected:
# - Camera matrix K generated
# - Distortion coefficients saved
# - YAML file created
```

### 8. Code Quality

```bash
# Linting
pylint src/ --rcfile=.pylintrc

# Type checking
mypy src/ --strict

# Expected: No critical errors, score ‚â•8.0/10
```

### 9. Documentation Review

- [ ] README.md c√≥ Installation instructions r√µ r√†ng
- [ ] README.md c√≥ Usage examples v·ªõi screenshots
- [ ] ARCHITECTURE.md m√¥ t·∫£ system design
- [ ] ALGORITHMS.md so s√°nh pros/cons t·ª´ng algorithm
- [ ] CALIBRATION.md c√≥ step-by-step guide
- [ ] All public functions c√≥ docstrings

### 10. Production Readiness Checklist

- [ ] Error handling: Try/catch cho file I/O, camera access
- [ ] Logging: Debug info, errors logged properly
- [ ] Config: User c√≥ th·ªÉ override parameters
- [ ] Graceful degradation: Fallback n·∫øu GPU kh√¥ng c√≥
- [ ] User feedback: Progress bar, status messages
- [ ] Exit handling: Proper cleanup (close camera, windows)

---

## ‚úÖ DEFINITION OF DONE

Project ƒë∆∞·ª£c coi l√† **COMPLETE** khi:

1. ‚úÖ T·∫•t c·∫£ tasks P0-P10 ƒë√£ complete
2. ‚úÖ Phase X verification checklist 100% pass
3. ‚úÖ Performance benchmarks ƒë·∫°t target (‚â•10 FPS cho ORB/720p tr√™n CPU)
4. ‚úÖ Cross-platform tests pass (macOS + Windows)
5. ‚úÖ Code coverage ‚â•70%
6. ‚úÖ Documentation ƒë·∫ßy ƒë·ªß (README, ARCHITECTURE, ALGORITHMS)
7. ‚úÖ User c√≥ th·ªÉ ch·∫°y app trong <5 ph√∫t t·ª´ clone repo

---

## üìå Risk Mitigation

| Risk                       | Probability | Impact | Mitigation Strategy                                                  |
| -------------------------- | ----------- | ------ | -------------------------------------------------------------------- |
| CPU performance kh√¥ng ƒë·ªß   | Medium      | High   | Optimize early (P8), reduce keypoints, downscale resolution n·∫øu c·∫ßn  |
| Monocular scale ambiguity  | High        | High   | Implement multiple scale estimation strategies, document limitations |
| Drift accumulation         | High        | High   | Add loop closure detection (future), benchmark drift metrics         |
| Cross-platform GUI issues  | Medium      | Medium | Use platform-agnostic framework (Tkinter safer than PyQt)            |
| SIFT patent issues         | Low         | Low    | SIFT free in OpenCV 4.4+, document license                           |
| Multi-threading complexity | Medium      | Medium | Thorough testing, use thread-safe data structures                    |

---

## üìù Notes

- **Monocular VO limitations:** Scale ambiguity l√† fundamental problem. Trajectory shape ƒë√∫ng nh∆∞ng scale c√≥ th·ªÉ sai. Document r√µ limitation n√†y.
- **CPU-only:** ƒê∆°n gi·∫£n setup h∆°n GPU, nh∆∞ng FPS th·∫•p h∆°n. T·ªëi ∆∞u b·∫±ng multi-threading v√† gi·∫£m s·ªë keypoints.
- **Algorithm tradeoffs:**
    - FAST: Nhanh nh·∫•t, √≠t descriptor info
    - ORB: Balance t·ªët speed/accuracy
    - SIFT: Ch·∫≠m nh∆∞ng robust nh·∫•t
    - Lucas-Kanade: Nhanh, smooth tracking nh∆∞ng kh√¥ng handle large motion
- **Future enhancements:** Stereo VO, Loop closure, Bundle adjustment, Deep learning features (SuperPoint)

---

**T·∫°o b·ªüi:** `project-planner` agent  
**Ng√†y:** 2026-01-30  
**Tr·∫°ng th√°i:** üü° Waiting for user approval
