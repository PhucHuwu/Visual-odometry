# Visual Odometry System Architecture

## ğŸ“ Tá»•ng Quan Kiáº¿n trÃºc

Há»‡ thá»‘ng Visual Odometry Ä‘Æ°á»£c thiáº¿t káº¿ theo kiáº¿n trÃºc modular vá»›i cÃ¡c layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Main Entry Point                   â”‚
â”‚                     (main.py)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VO Pipeline Orchestrator                â”‚
â”‚               (vo_pipeline.py)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camera  â”‚  â”‚Preproc â”‚ â”‚Algorithmsâ”‚ â”‚  Motion    â”‚
â”‚ Input   â”‚  â”‚        â”‚ â”‚          â”‚ â”‚ Estimation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                             â”‚              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚        Trajectory Manager          â”‚
              â”‚         (trajectory.py)            â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© Components Chi Tiáº¿t

### 1. Core Layer

#### `camera.py` - Camera Input Handler

- **Chá»©c nÄƒng:** Xá»­ lÃ½ input tá»« webcam hoáº·c video file
- **Features:**
    - Support cáº£ live camera vÃ  video file
    - Auto resize frame
    - Progress tracking cho video file
    - Context manager support (with statement)

#### `preprocessor.py` - Image Preprocessing

- **Chá»©c nÄƒng:** Tiá»n xá»­ lÃ½ áº£nh
- **Pipeline:**
    1. BGR â†’ Grayscale conversion
    2. Optional: Gaussian blur Ä‘á»ƒ denoise

#### `trajectory.py` - Trajectory Management

- **Chá»©c nÄƒng:** TÃ­ch lÅ©y vÃ  quáº£n lÃ½ camera pose history
- **Algorithm:**
    ```
    T_world = T_world * T_current
    position += rotation_world @ translation_current
    ```
- **Features:**
    - History limit (trÃ¡nh memory overflow)
    - Save/load trajectory

#### `vo_pipeline.py` - Main Pipeline Orchestrator

- **Chá»©c nÄƒng:** Äiá»u phá»‘i toÃ n bá»™ VO process
- **Flow:**
    ```
    Frame â†’ Undistort â†’ Preprocess â†’ Feature Detection/Tracking
      â†’ Essential Matrix â†’ Pose Recovery â†’ Trajectory Update
    ```

### 2. Algorithms Layer

#### Base Architecture

```python
BaseAlgorithm (ABC)
    â”œâ”€â”€ detect(image) â†’ (keypoints, descriptors)
    â”œâ”€â”€ match(kp1, desc1, kp2, desc2) â†’ matches
    â””â”€â”€ extract_matched_points(kp1, kp2, matches) â†’ (pts1, pts2)
```

#### Implementations

1. **FAST Detector** (`fast_detector.py`)
    - Detection: FAST corners
    - Description: ORB descriptors
    - Matching: BFMatcher vá»›i Hamming distance
    - Pros: Nhanh nháº¥t (15-20 FPS)
    - Cons: Ãt robust vá»›i scale/rotation changes

2. **ORB Detector** (`orb_detector.py`)
    - Detection: Oriented FAST
    - Description: Rotated BRIEF (256-bit binary)
    - Matching: BFMatcher vá»›i Hamming distance
    - Pros: Balance tá»‘t speed/accuracy
    - Cons: Limited scale invariance

3. **SIFT Detector** (`sift_detector.py`)
    - Detection: DoG (Difference of Gaussians)
    - Description: 128-dim float descriptors
    - Matching: BFMatcher vá»›i L2 distance
    - Pros: Scale/rotation invariant, robust nháº¥t
    - Cons: Cháº­m nháº¥t (6-10 FPS)

4. **Lucas-Kanade Optical Flow** (`lk_optical_flow.py`)
    - Tracking: Sparse optical flow
    - Initial detection: FAST corners
    - Matching: N/A (tracking-based)
    - Pros: Smooth tracking, nhanh (20-25 FPS)
    - Cons: KhÃ´ng handle large motion, keypoint drift

### 3. Motion Estimation Layer

#### `essential_matrix.py`

- **Algorithm:** 5-point algorithm vá»›i RANSAC
- **Input:** Matched points + camera matrix K
- **Output:** Essential Matrix E + inlier mask
- **Validation:** Kiá»ƒm tra rank(E) = 2

#### `pose_estimation.py`

- **Algorithm:** Decompose E thÃ nh 4 solutions, chá»n valid solution
- **Input:** E + matched points + K
- **Output:** R (3x3 rotation) + t (3x1 translation, unit vector)
- **Validation:**
    - det(R) = 1
    - R^T \* R = I

#### `scale_estimation.py`

- **Problem:** Monocular VO cÃ³ scale ambiguity
- **Methods:**
    - Constant velocity assumption
    - Unit scale (default)
    - Median depth heuristic
- **Limitation:** Absolute scale khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c

### 4. Utilities Layer

#### `config_loader.py`

- Load YAML configs
- Nested key access: `config.get("camera.fx")`
- Runtime override support

#### `logger.py`

- File + console logging
- Log rotation (10MB per file)
- Configurable levels

#### `calibration.py`

- Camera calibration tá»« checkerboard
- Undistortion
- Load/save calibration parameters

## ğŸ“Š Data Flow

### Normal Operation (Feature Matching)

```
Frame N-1                           Frame N
    â”‚                                  â”‚
    â”œâ”€â”€â–º Detect Features              â”‚
    â”‚    (FAST/ORB/SIFT)               â”‚
    â”‚        â”‚                          â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                       â”‚
    â”‚                   Match Features
    â”‚                   (BFMatcher + Ratio Test)
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚                Matched Points (pts1, pts2)
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚             Estimate Essential Matrix E
    â”‚             (RANSAC, inlier filtering)
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚                 Recover Pose (R, t)
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚                 Scale Estimation
    â”‚                       â”‚
    â”‚                       â–¼
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Update Trajectory
```

### Optical Flow Tracking

```
Frame N-1                           Frame N
    â”‚                                  â”‚
    â”œâ”€â”€â–º Detect Keypoints             â”‚
    â”‚    (FAST)                        â”‚
    â”‚        â”‚                          â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                       â”‚
    â”‚              Track Keypoints
    â”‚              (calcOpticalFlowPyrLK)
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚                Tracked Points (pts1, pts2)
    â”‚                       â”‚
    â”‚             (TÆ°Æ¡ng tá»± nhÆ° trÃªn)
    â”‚                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
```

## âš™ï¸ Configuration Hierarchy

```
default_config.yaml
    â”œâ”€â”€ video: source, resolution, FPS
    â”œâ”€â”€ algorithm: type selection
    â”œâ”€â”€ camera: calibration file path
    â”œâ”€â”€ visualization: display options
    â”œâ”€â”€ performance: threading, profiling
    â””â”€â”€ logging: level, file, rotation

algorithm_config.yaml
    â”œâ”€â”€ fast: threshold, nonmaxSuppression
    â”œâ”€â”€ orb: nfeatures, scaleFactor, nlevels
    â”œâ”€â”€ sift: nfeatures, contrastThreshold
    â”œâ”€â”€ lucas_kanade: winSize, maxLevel
    â””â”€â”€ matching: ratio_test, ransac_threshold

camera_params.yaml
    â”œâ”€â”€ camera_matrix: fx, fy, cx, cy
    â”œâ”€â”€ distortion_coefficients: k1, k2, k3, p1, p2
    â””â”€â”€ image_size: width, height
```

## ğŸ”„ State Management

### VO Pipeline State

```python
prev_image: np.ndarray           # Previous frame (grayscale)
prev_keypoints: List[KeyPoint]   # Previous keypoints
prev_descriptors: np.ndarray     # Previous descriptors
frame_count: int                 # Total frames processed
```

### Trajectory State

```python
positions: List[np.ndarray]      # History of 3D positions
orientations: List[np.ndarray]   # History of rotation matrices
current_position: np.ndarray     # Current camera position
current_rotation: np.ndarray     # Current camera orientation
```

## ğŸš¨ Error Handling

### Pipeline Failures

1. **KhÃ´ng Ä‘á»§ keypoints:**
    - Skip frame, continue vá»›i frame tiáº¿p theo
    - Log warning

2. **Essential Matrix estimation tháº¥t báº¡i:**
    - Skip frame
    - KhÃ´ng update trajectory

3. **Pose recovery tháº¥t báº¡i:**
    - Kiá»ƒm tra rotation matrix validity
    - Skip náº¿u invalid

### Recovery Strategies

- **Keypoint depletion:** Re-detect keypoints (LK tracking)
- **Low inlier ratio:** Increase RANSAC threshold (runtime)
- **Drift accumulation:** Log drift metrics, document limitation

## ğŸ“ˆ Performance Optimization

### CPU Optimization (Implemented)

1. **NumPy vectorization:** Matrix operations
2. **Multi-threading potential:**
    - Thread 1: Frame capture
    - Thread 2: Feature detection
    - Thread 3: Visualization (future)

### Future Optimizations

1. **GPU acceleration:** OpenCV CUDA modules
2. **Keypoint reduction:** Adaptive nfeatures based on FPS
3. **Frame skipping:** Process every Nth frame
4. **Resolution downscaling:** Trade accuracy for speed

## ğŸ” Testing Strategy

### Unit Tests

- `test_algorithms.py`: Test tá»«ng algorithm
- `test_motion_estimation.py`: Test E, R, t estimation
- `test_preprocessing.py`: Test grayscale, denoise

### Integration Tests

- `test_integration.py`: End-to-end pipeline test
- Verify trajectory shape vá»›i known motion

### Performance Benchmarks

- `benchmark.py`: FPS cho tá»«ng algorithm
- Compare CPU vs theoretical limits

## ğŸ“š References

### Algorithms

- FAST: [Rosten & Drummond, 2006]
- ORB: [Rublee et al., 2011]
- SIFT: [Lowe, 2004]
- Lucas-Kanade: [Lucas & Kanade, 1981]

### Visual Odometry

- [Scaramuzza & Fraundorfer, 2011] - Visual Odometry Tutorial
- [NistÃ©r, 2004] - 5-point algorithm cho E matrix
- [Hartley & Zisserman, 2004] - Multiple View Geometry

---

**Version:** 0.1.0  
**Last Updated:** 2026-01-30
